---
title: Insert title here
key: 972fe35ea4e257689c1ab53913553465

---
## Introduction to Logistic Regression

```yaml
type: "TitleSlide"
key: "618541c966"
```

`@lower_third`

name: **Michael Babawale PhD**
title: DataCamp Instructor 


`@script`
In this lesson, I will explain the reasoning behind Logistic Regression. Also, we will discuss the meaning of a decision boundary, and how it applies to logistic regression.


---
## **__Principles of Logistic Regression__**

```yaml
type: "FullSlide"
key: "d549d6df65"
```

`@part1`
- **Logistic Regression is useful for classification**{{1}} 

- **In logistic regression, the response or target variable _(y)_ is qualitative** {{2}}

- **In addition, logistic regression models are probabilistic i.e., the model predicts the probability that _y_ belongs to a particular class.** {{3}}

- **Logistic Regression is a linear classifier, i.e, the model creates a '_linear decision boundary_' ** {{4}}


`@script`
Logistic Regression models fall under the classification section of supervised machine learning. Thus, for logistic regression, the target variable is of a qualitative type. However, the features can be either quantitative or qualitative.

An important thing to note about a Logistic Regression model is that it does not model the target variable directly, rather, it models the probability that the target variable belongs to a particular class or category


---
## **What is a linear decision boundary?**

```yaml
type: "FullSlide"
key: "99ea2434a6"
disable_transition: false
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4326/datasets/af94e6f5f300d85f449a0fffb44a277f7f4afd6f/decisionboundary2.PNG)


`@script`
Consider a simple example of a data which contains 2 features, named 'Feature 0' and 'Feature 1'. in addition, the classification type is binary as it contains two separate classes 'A' and 'B'


---
## **What is a linear decision boundary?**

```yaml
type: "FullSlide"
key: "c13e2674a6"
disable_transition: true
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4326/datasets/a808bf331e7878228ba2c1188b4372f9106e7180/decisionboundary.png)


`@script`
Logistic regression fits a model to the data by fitting a straight line such that points on one side of the line correspond to one category or class, and points on another side of the line correspond to another class or category.  This line is called the decision boundary. In logistic regression, the decision boundary for classification is a straight line, hence it is called a linear decision boundary.


---
## ** Predicted probability of each class**

```yaml
type: "FullCodeSlide"
key: "11a6d88e35"
```

`@part1`
```
`from sklearn.datasets import load_breast_cancer 

`from sklearn.linear_model import LogisticRegression 

`breast_cancer` = load_breast_cancer()

`X` = breast_cancer.data, `y` = breast_cancer.target

`X_2` = X[:, 0:2]

`clf` = LogisticRegression().fit(X_2,y)

`clf.predict_proba(X_2)

```{{1}}

![](https://assets.datacamp.com/production/repositories/4326/datasets/85cf14e62d87ab48a520a9579421cf1fac2c3002/predict_proba.PNG) {{2}}


`@script`
I said earlier that logistic regression does not only predict classes, but also the probability that a data point belongs to each class. 

To show an example of this, we import a dataset from scikit-learn,as shown in Line 1. The LogisticRegression function is then imported in Line 2. In Line 3, the dataset is initialized to a variable. In line 4,we initialize both the feature data X and the target variable y. In line 5, 2 features were selected from the feature set to simplify the model we create. In line 6, we fit a LogisticRegression model called 'clf' to the simplified data using the fit() method. In line 7, we calculate the predicted probability of each class from the feature set using the .predict_proba() function.

The result of predict_proba() is an array with the same size as the feature data set. The first value in each array corresponds to the predicted probability of the first class, and the second value in each array corresponds to the predicted probability of the second class. The value shown by .predict_proba() is always between 0 and 1, and the values in each row of the array always add up to 1. Any class with above 50% probability is the predicted class.


---
## Quiz

```yaml
type: "FinalSlide"
key: "cd8a045234"
```

`@script`
Now, let's practice the key concepts we talked about in this lesson

